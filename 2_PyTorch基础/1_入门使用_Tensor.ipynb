{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4c0eae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1.10.2+cu113'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "396a70cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tensor\n",
    "张量是一个统称，其中包含很多类型：是一个可以包含高维数据的统称的一个数据结构（类型）\n",
    "\n",
    "1. 0阶张量：标量, scaler、常数，0-D Tensor . 在计算loss中, 返回的就是一个标量.\n",
    "\n",
    "2. 1阶张量：向量 vector，1-D Tensor \n",
    "\n",
    "3. 2阶张量：矩阵 matrix，2-D Tensor\n",
    "\n",
    "4. 3阶张量\n",
    "\n",
    "5. ...\n",
    "\n",
    "6. N阶张量\n",
    "\n",
    "   这个阶也称之为维度, 即shape个数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d581216",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 在python中创建Tensor\n",
    "# 首先要区分的是torch.Tensor() 和 torch.tensor()\n",
    "# 首先大写的Tensoe是类, 一般来说是传入形状然后生成未初始化的tensor. 我们可以通过类直接创建不同类型的tensor\n",
    "# 而小的的tensor是方法, 一般来说是传入数据, 直接生成tensor. 我们可以指定dtype来控制数据类型\n",
    "# 接下来我们就使用torch中的方法创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 3],\n        [1, 4]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用python中的list创建tensor\n",
    "t1 = torch.tensor([[1, 3], [1, 4]])\n",
    "t1.dtype # torch.int64\n",
    "t1\n",
    "# tensor([[1, 3],\n",
    "        # [1, 4]])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18330837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3.],\n        [4., 5., 6.]], dtype=torch.float64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  使用数据直接创建tensor\n",
    "torch.tensor(np.array(\n",
    "    [[1, 2, 3],  \n",
    "     [4, 5, 6]],\n",
    "     dtype=np.float64 # 在np中指定dtype类型\n",
    ")) # 那么生成的tensor类型也是与np类型相同的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12404482",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 2.8026e-45, 0.0000e+00],\n        [1.1210e-44, 0.0000e+00, 1.4013e-45],\n        [0.0000e+00, 0.0000e+00, 1.0469e-38]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Torch的API创建tensor：\n",
    "# 1. 创建一个空的tenosr变量, 未初始化, 会用无用数据进行填充\n",
    "torch.empty([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2489bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全为1 的tensor\n",
    "torch.ones([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ab0413",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全为0的tensor\n",
    "torch.zeros([4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12d5646",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定数值创建:\n",
    "# 例子: 创建一个4*5的矩阵, 并全部用10进行填充\n",
    "torch.full([4 ,5],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3831343",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6.8679, 6.0127, 7.9359],\n        [5.6682, 5.2238, 9.7485],\n        [9.7179, 9.8773, 7.2079],\n        [7.8719, 6.3506, 6.0374]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机创建_创建一个矩阵, 符合均匀分布, 范围: [0, 1)\n",
    "torch.rand(size=(4, 3))\n",
    "# 如果要创建到固定范围内: [a, b)\n",
    "a = 5\n",
    "b = 10\n",
    "\n",
    "(b-a) * torch.rand(size=(4, 3)) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6, 5, 4, 8, 5, 9],\n        [6, 7, 4, 6, 7, 8],\n        [7, 7, 6, 4, 7, 8],\n        [6, 7, 3, 6, 5, 4]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建随机整数:\n",
    "# 创建整数, 同样符合均匀分布\n",
    "torch.randint(low=3, high=10, size=(4, 6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.1252, -0.7768, -0.8509],\n        [-0.5744,  0.2997,  0.5756],\n        [ 0.1134, -0.9553,  0.1004],\n        [-1.0517,  2.0844,  2.5523]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建随机tensor, 符合标准正态分布:\n",
    "torch.randn(size=(4, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[11.1677],\n        [ 8.0804],\n        [12.2535],\n        [13.4908],\n        [10.5689],\n        [10.2360],\n        [14.0248],\n        [ 2.9045],\n        [10.2188],\n        [ 2.4084]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以让每个元素, 都服从不同的正太分布:\n",
    "torch.normal(\n",
    "    mean=torch.full(size=(10, 1), fill_value=10.),\n",
    "    std=torch.full(size=(10,1), fill_value=4.0)\n",
    ")\n",
    "# 注意, 必须是类型是一样的,并且大小也要是一样的.\n",
    "# 可以都指定为Float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tensor的常用方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当tensor中只有一个元素的时候, 我们可以直接使用该方法获取其中的元素值\n",
    "# 不用在一层一层索引了\n",
    "t2 = torch.tensor([[1]], dtype=torch.float32)\n",
    "t2 # 此时如果我们需要取出里面的值我们需要一层一层索引:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但是我们可以直接使用: item()就直接可以得到其中的元素值\n",
    "t2.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1698, -1.4021,  0.8972, -0.9803],\n        [ 0.1119, -1.0663,  1.8746, -0.0616],\n        [ 1.0974,  1.2527, -0.4841,  0.1457]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为numpy数组\n",
    "t3 = torch.randn(size=(3, 4))\n",
    "t3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3.numpy(): [[ 0.16983157 -1.4021273   0.8972213  -0.9803232 ]\n",
      " [ 0.11193099 -1.0662715   1.874605   -0.06164317]\n",
      " [ 1.0973673   1.2527341  -0.4841227   0.14570478]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"t3.numpy():\",t3.numpy()) # 直接从tensor 转换到 ndarray\n",
    "print(type(t3.numpy())) # 直接就是原地修改了。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 20])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取形状\n",
    "t4 = torch.Tensor(size=(10, 20))\n",
    "t4.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.float64"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类型的变换:\n",
    "print(t4.double().dtype)\n",
    "t4 = t4.double() # 但是类型的修改不是原地修改, 所以我们需要再赋值\n",
    "t4.dtype #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1.]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor的其他操作\n",
    "# torch.*_like(A) # 创建一个与A形状相同的一个tensor对象\n",
    "# 例如:\n",
    "t4_like = torch.ones_like(t4)\n",
    "t4_like # 就是创建一个与t4形状相同的全1 矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor.new_*(A) # 用于创建一个与A同类型的的tensor对象\n",
    "t4.new_ones(size=(5,3), dtype=torch.float64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.9525e-310, 6.9525e-310, 6.9525e-310],\n",
      "        [6.9525e-310, 6.9525e-310, 6.9525e-310],\n",
      "        [6.9525e-310, 6.9525e-310, 6.9525e-310],\n",
      "        [6.9525e-310, 6.9525e-310, 6.9525e-310]], dtype=torch.float64)\n",
      "tensor([[ 1.0649, -1.5081,  1.6303],\n",
      "        [ 0.6871,  1.0619, -0.0838],\n",
      "        [ 1.8371, -1.7209,  1.0924],\n",
      "        [-0.8186,  0.4940, -0.0023]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# tensor的其他操作.\n",
    "# tensor和tensor相加:\n",
    "a = torch.DoubleTensor(size=(4, 3))\n",
    "b = torch.randn_like(a)\n",
    "print(a)\n",
    "print(b) # 创建了和a一样size和dtype的tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}